{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuralnetwork_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n",
        "!pip3 install 'Pillow'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "from torchvision.datasets import VisionDataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxSSsNvYIkm4",
        "colab_type": "text"
      },
      "source": [
        "**Define the Dataset class, i.e. Symbols** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4WdopUrIbm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABELS = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'div', 'equal', 'minus', 'mul', 'plus']\n",
        "\n",
        "def get_squared_img(image_pil):\n",
        "    # Convert PIL image -> OpenCV image (1. Convert into Numpy array, 2. Convert RGB to BGR)\n",
        "    image = np.array(image_pil)\n",
        "    image = image[:, :, ::-1].copy()\n",
        "\n",
        "    # Fit the image in a squared area\n",
        "    height = image.shape[0]\n",
        "    width = image.shape[1]\n",
        "    size = max(height, width)\n",
        "    image_prepared = np.zeros((size, size, 3), dtype=np.uint8)\n",
        "    image_prepared[:, :] = (255, 255, 255)\n",
        "    y_start = int((size-height)/2)\n",
        "    x_start = int((size-width)/2)\n",
        "    y_end = y_start + height\n",
        "    x_end = x_start + width\n",
        "    image_prepared[y_start:y_end, x_start:x_end] = image\n",
        "\n",
        "    # Convert OpenCV image -> PIL image \n",
        "    image_prepared = cv.cvtColor(image_prepared, cv.COLOR_BGR2RGB)\n",
        "    image_pil = Image.fromarray(image_prepared) \n",
        "\n",
        "    return image_pil\n",
        "\n",
        "def pil_loader(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        # Read the image from the filesystem \n",
        "        img = Image.open(f)\n",
        "        img = img.convert('RGB')\n",
        "        squared_img = get_squared_img(img)\n",
        "        return squared_img\n",
        "\n",
        "class Symbols(VisionDataset):\n",
        "    def __init__(self, root, split=\"train\", transform=None):\n",
        "        '''\n",
        "        __init__ creates the class containing the dataset (it contains an array of (pil_image, label) pairs)\n",
        "        '''\n",
        "        super(Symbols, self).__init__(root, transform=transform)        \n",
        "\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.data = [] \n",
        "\n",
        "        if split == \"train\":\n",
        "            rootdir = root + \"train/\"\n",
        "        elif split == \"eval\":\n",
        "            rootdir = root + \"eval/\"\n",
        "\n",
        "        for root, subdirs, files in os.walk(rootdir):\n",
        "          #print('--\\nroot = ' + root)\n",
        "          #for subdir in subdirs:\n",
        "              #print('\\t- subdirectory ' + subdir)\n",
        "\n",
        "          for filename in files:\n",
        "              file_path = os.path.join(root, filename)\n",
        "              #print('\\t- file %s (full path: %s)' % (filename, file_path))\n",
        "\n",
        "              # Get the class label from the directory name\n",
        "              root_tmp = root\n",
        "              label = root_tmp.replace(rootdir, \"\")\n",
        "\n",
        "              #print('Adding the pair... ({}, {})'.format(filename, label))\n",
        "\n",
        "              # Retrieve the index of the label of the current image\n",
        "              label_index = LABELS.index(label)\n",
        "\n",
        "              obj = (pil_loader(file_path), label_index)\n",
        "              self.data.append(obj)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        __getitem__ should access an element through its index\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (pil_image, label) \n",
        "        '''\n",
        "\n",
        "        image = self.data[index][0]\n",
        "        label = self.data[index][1]\n",
        "\n",
        "        # Applies preprocessing when accessing the image\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        __len__ returns the length of the dataset\n",
        "        '''\n",
        "        length = len(self.data)\n",
        "        return length\n",
        "\n",
        "    def retrieveArrayForDebug(self):\n",
        "      return self.data\n",
        "      \n",
        "    def retrieveLabelsForDebug(self):\n",
        "      return self.labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda'      # 'cuda' or 'cpu'\n",
        "\n",
        "NUM_CLASSES = 15\n",
        "\n",
        "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "LR = 1e-2            # Initial Learning Rate \n",
        "\n",
        "# NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "# NUM_EPOCHS = 40      # Variation of the total number of training epochs\n",
        "NUM_EPOCHS = 50      # Other variation of the total number of training epochs\n",
        "\n",
        "STEP_SIZE = 30       # How many epochs before decreasing learning rate (if using a step-down policy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Define transforms for training phase (NO DATA AUGMENTATION)\n",
        "# data_transform = transforms.Compose([transforms.Resize(224),          # Resizes short size of the PIL image to 224\n",
        "#                                       transforms.ToTensor(),          # Turn PIL Image to torch.Tensor\n",
        "#                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "# ])\n",
        "\n",
        "# # Define transforms for training phase (DATA AUGMENTATION - RandomRotation(10))\n",
        "# data_transform = transforms.Compose([transforms.Resize(224),          # Resizes short size of the PIL image to 224\n",
        "#                                       transforms.RandomRotation(10),  # Rotate the image by a random angle\n",
        "#                                       transforms.ToTensor(),          # Turn PIL Image to torch.Tensor\n",
        "#                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "# ])\n",
        "\n",
        "# Define transforms for training phase (DATA AUGMENTATION - RandomRotation(15))\n",
        "data_transform = transforms.Compose([transforms.Resize(224),          # Resizes short size of the PIL image to 224\n",
        "                                      transforms.RandomRotation(15),  # Rotate the image by a random angle\n",
        "                                      transforms.ToTensor(),          # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "\n",
        "# Define transforms for validation phase \n",
        "eval_transform = transforms.Compose([transforms.Resize(224),      # Resizes short size of the PIL image to 224\n",
        "                                     transforms.ToTensor(),       # Turn PIL Image to torch.Tensor\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./IPCV-Camera-Calculator'):\n",
        "  !git clone https://github.com/ilagioda/IPCV-Camera-Calculator.git\n",
        "\n",
        "DATA_DIR = 'IPCV-Camera-Calculator/dataset/'\n",
        "\n",
        "# Prepare Pytorch train/val datasets\n",
        "train_dataset = Symbols(DATA_DIR, split=\"train\", transform=data_transform) \n",
        "val_dataset = Symbols(DATA_DIR, split=\"eval\", transform=data_transform)\n",
        "\n",
        "# DEBUG Check dataset sizes\n",
        "# print('Train Dataset: {}'.format(len(train_dataset)))\n",
        "# print('Validation Dataset: {}'.format(len(val_dataset)))\n",
        "\n",
        "# DEBUG\n",
        "# arr = train_dataset.retrieveArrayForDebug()\n",
        "# print(arr[600][1])\n",
        "# lab = train_dataset.retrieveLabelsForDebug()\n",
        "# print(lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load AlexNet model\n",
        "net = alexnet()\n",
        "\n",
        "# Change the last layer of AlexNet to output NUM_CLASSES classes\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)    # nn.Linear in pytorch is a fully connected layer\n",
        "                                                    # The convolutional layer is nn.Conv2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function (for classification, we use Cross Entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Choose parameters to optimize\n",
        "# To access a different set of parameters, you have to access submodules of AlexNet\n",
        "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
        "# e.g.: parameters of the convolutional layers: net.features.parameters()\n",
        "# In this case, we optimize over all the parameters of AlexNet\n",
        "parameters_to_optimize = net.parameters()\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "**Train on the training set and evaluate on the validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# By default, everything is loaded to CPU\n",
        "net = net.to(DEVICE)      # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark     # Calling this optimizes runtime\n",
        "\n",
        "# Initialize the best accuracy\n",
        "best_acc = -1\n",
        "best_epoch = -1\n",
        "\n",
        "\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  for images, labels in train_dataloader:\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train()   # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "\n",
        "  # Evaluation of the model on the validation set\n",
        "  running_corrects = 0\n",
        "  for images, labels in tqdm(val_dataloader):\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(val_dataset))\n",
        "  print('Validation Accuracy: {} %'.format(accuracy*100))\n",
        "\n",
        "  # Check if a better accuracy has been found\n",
        "  if accuracy > best_acc:\n",
        "\n",
        "    # Update the accuracy and the epoch\n",
        "    best_acc = accuracy\n",
        "    best_epoch = epoch + 1\n",
        "\n",
        "    # Save the parameters of the best model\n",
        "    best_net = copy.deepcopy(net)\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step() \n",
        "\n",
        "# Print the best accuracy on validation set\n",
        "print(\"Best accuracy on validation set (found at epoch {}/{} and with initial LR={}): {} %\".format(best_epoch, NUM_EPOCHS, LR, best_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0_HlC4lcRJD",
        "colab_type": "text"
      },
      "source": [
        "**Prepare the finetuning on the validation set**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJAbuxU_cLCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose parameters to optimize\n",
        "parameters_to_optimize = best_net.parameters()\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvHTE-nlQ86f",
        "colab_type": "text"
      },
      "source": [
        "**Finetuning the best model on the validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0X8o6yJeRA0X",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# By default, everything is loaded to CPU\n",
        "best_net = best_net.to(DEVICE)   # this will bring the best network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark   # Calling this optimizes runtime\n",
        "\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  for images, labels in val_dataloader:\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    best_net.train()    # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad()       # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = best_net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8dJ0H3d979F",
        "colab_type": "text"
      },
      "source": [
        "**Save the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHrROw0a97rN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './NN.pth'\n",
        "torch.save(best_net.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}